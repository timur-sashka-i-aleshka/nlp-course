{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3 [10 баллов] \n",
    "# До 30.04.18 23:59\n",
    "\n",
    "Задание выполняется в группе (1-4 человека). В случае использования какого-либо строннего источника информации обязательно дайте на него ссылку (поскольку другие тоже могут на него наткнуться). Плагиат наказывается нулём баллов за задание и предвзятым отношением в будущем.\n",
    "\n",
    "Не все части обязательны для выполнения, однако вы можете быть дополнительно оштрафованы за небрежное за выполнение одной или двух частей вместо четырех.\n",
    "\n",
    "При возниконовении проблем с выполнением задания обращайтесь с вопросами к преподавателю. Поэтому настоятельно рекомендуется выполнять задание заранее, оставив запас времени на всевозможные технические проблемы. Если вы начали читать условие в последний вечер и не успели из-за проблем с установкой какой-либо библиотеки — это ваши проблемы.\n",
    "\n",
    "\n",
    "Результат выполнения задания — это отчёт в формате html на основе Jupyter Notebook. Нормальный отчёт должен включать в себя:\n",
    "* Краткую постановку задачи и формулировку задания\n",
    "* Описание **минимума** необходимой теории и/или описание используемых инструментов - не стоит переписывать лекции или Википедию\n",
    "* Подробный пошаговый рассказ о проделанной работе\n",
    "* Аккуратно оформленные результаты\n",
    "* **Внятные выводы** – не стоит относится к домашнему заданию как к последовательности сугубо технических шагов, а стоит относится скорее как к небольшому практическому исследованию, у которого есть своя цель и свое назначение.\n",
    "\n",
    "Небрежное его оформление отчета существенно отразится на итоговой оценке. Весь код из отчёта должен быть воспроизводимым, если для этого нужны какие-то дополнительные действия, установленные модули и т.п. — всё это должно быть прописано в тексте в явном виде.\n",
    "\n",
    "Сдача отчетов осуществляется через систему AnyTask.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование архитектуры SENNA для определения части речи\n",
    "\n",
    "Домашнее задание написано по мотивам работы R. Collobert:\n",
    "\n",
    "**Collobert, Ronan, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. \"Natural language processing (almost) from scratch.\" Journal of Machine Learning Research 12, no. Aug (2011): 2493-2537.**\n",
    "\n",
    "В этом домашнем задании вам предстоит самостоятельно разработать архитектуру SENNA для определения части речи. \n",
    "SENNA – это простая архитектура нейронной сети, позволяющая достигнуть state-of-the-art результатов в нескольких задачах обработки текстов.  \n",
    "\n",
    "Использование SENNA для определения части речи предполагает, что задача определения части речи для данного слова формулируется как задача классификации: пусть в размеченном корпусе всего $|T|$ (= tagset) различных тегов частей речи, тогда каждое слово $w$ относится к одному из $T$ классов. Для каждого слова из обучающих данных формируется собственный вектор признаков. Нейронная сеть обучается по всем векторам признаков для слов из обучающего множества. \n",
    "\n",
    "Подход к решению задачи классификации представлен в оригинальной статье на рис. 1 (Figure 1: Window approach network). Он состоит из следующих шагов (раздел 3.3.1):\n",
    "1. Каждое слово представляется эмбеддингом: $w_i \\rightarrow LT_{w^i}$, размерность эмбеддинга - $d$;\n",
    "2. Для каждого слова формируется окно длины $k$ из $(k-1)/2$ соседних слов слева от данного слова  и $(k-1)/2$ соседних слов справа от данного слова, $k$ – нечетное. \n",
    "3. Для каждого слова формируется вектор признаков, состоящий из конкатенированных эмбеддингов слов из левого окна, данного слова и слов из правого окна. Итоговая размерность вектора признаков – $d \\times k$. Именно этот вектор подается на вход нейронной сети;\n",
    "4. Обучается нейронная сеть, имеющая один скрытый слой с $n_h$ нейроннами и нелинейной функцией активации $\\theta$;\n",
    "5. На выходном слое нейронной сети решается задача классификации на |T| классов, то есть, определяется часть речи для каждого слова. \n",
    "\n",
    "Если для слова невозможно найти $(k-1)/2$ соседних слов слева от данного слова  и $(k-1)/2$ соседних слов справа от данного слова – используется padding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "1. Открытый корпус: https://github.com/dialogue-evaluation/morphoRuEval-2017/blob/master/OpenCorpora_Texts.rar\n",
    "2. Предобученные эмбеддинги Facebook: https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.ru.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1 [2 балла] Подготовка данных\n",
    "1. Прочитайте размеченные данные Открытого корпуса, используя nltk.corpus.reader.conll.ConllCorpusReader\n",
    "2. Посчитайте количество предложений и число тегов частей речи;\n",
    "3. Сформируйте тестовое и обучающее множество: первые 3/4 данных – обучающее множество;\n",
    "\n",
    "Для каждого слова:\n",
    "1. Определите его окно (слова слева и справа) размера $k$;\n",
    "2. Сформируйте его вектор признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ConllCorpusReader('.', ['unamb_sent_14_6.conllu'], ('ignore', 'words', 'ignore', 'pos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38508\n"
     ]
    }
   ],
   "source": [
    "sents = reader.tagged_sents()\n",
    "N = len(sents)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число тегов частей речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "all_pos = list(set(list(map(lambda x: x[1], reader.tagged_words()))))\n",
    "NUM_CLASSES = len(all_pos)\n",
    "print(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим предложения на обучающую и тестирующую часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = sents[:-N // 4]\n",
    "TEST = sents[-N // 4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функуции чтения эмбеддингов и подготовки датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(max_words = -1):\n",
    "    words = []\n",
    "    embeddings = []\n",
    "    file = open('wiki.ru.vec', 'r')\n",
    "    file.readline()\n",
    "    for i, line in enumerate(file):\n",
    "        if max_words != -1 and i >= max_words:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        split_result = line.rsplit(maxsplit=300)\n",
    "        word = split_result[0]\n",
    "        embedding = np.array(split_result[1:],dtype=float)\n",
    "        words.append(word)\n",
    "        embeddings.append(embedding)\n",
    "    return words, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(sents, word_to_idx, embeddings, pos_idx, k):\n",
    "    p = (k - 1) // 2\n",
    "    features = []\n",
    "    labels = []\n",
    "    for sent in sents:\n",
    "        u = 0\n",
    "        sent_embeddings = []\n",
    "        unknown_embedding = np.zeros(300, dtype=float)\n",
    "        sent_embeddings.extend([unknown_embedding] * p)\n",
    "        for word, tag in sent:\n",
    "            word = word.lower()\n",
    "            if word in word_to_idx:\n",
    "                word_embedding = embeddings[word_to_idx[word]]\n",
    "            else:\n",
    "                word_embedding = unknown_embedding\n",
    "            sent_embeddings.append(word_embedding)\n",
    "            labels.append(pos_idx[tag])\n",
    "            u += 1\n",
    "        sent_embeddings.extend([unknown_embedding] * p)\n",
    "        for i in range(u):\n",
    "            current = np.array(sent_embeddings[i:i + k])\n",
    "            features.append(current.flatten())\n",
    "    return np.array(features, dtype=float), np.array(labels,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_to_idx(words):\n",
    "    res = {}\n",
    "    for i, word in enumerate(words):\n",
    "        res[word] = i\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем эмбеддинги (ограничиваемся 50000 самых популярных слов) и формируем датасет к окном ширины 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, embeddings = read_embeddings(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = build_word_to_idx(words)\n",
    "pos_idx = build_word_to_idx(all_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "X_train, Y_train = prepare_dataset(TRAIN, word_to_idx, embeddings, pos_idx, k)\n",
    "X_test, Y_test = prepare_dataset(TEST, word_to_idx, embeddings, pos_idx, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2 [4 баллов] Архитектура нейронной сети\n",
    "\n",
    "Архитектура нейронной сети состоит из следующих слов:\n",
    "1. Входной слой: нейронная сеть получает на вход вектор признаков, состоящий из $k$ конкатенированных эмбеддингов;/\n",
    "2. Скрытый слой: $n_h$ нейронов и нелинейная функция активации $\\theta$;\n",
    "3. Выходной слой:  $|T|$ нейронов для итоговой классификации.\n",
    "\n",
    "Обучите нейронную сеть на обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_h, k, act):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_h, activation=act, input_shape=(k * 300,)))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(128, k, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 25s 79us/step - loss: 0.3827 - acc: 0.8721 - val_loss: 0.4079 - val_acc: 0.8576\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 24s 76us/step - loss: 0.2860 - acc: 0.9003 - val_loss: 0.3814 - val_acc: 0.8679\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 26s 82us/step - loss: 0.2583 - acc: 0.9093 - val_loss: 0.3755 - val_acc: 0.8691\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 29s 91us/step - loss: 0.2406 - acc: 0.9149 - val_loss: 0.3825 - val_acc: 0.8716\n",
      "Epoch 5/1000\n",
      "315319/315319 [==============================] - 30s 94us/step - loss: 0.2267 - acc: 0.9190 - val_loss: 0.3854 - val_acc: 0.8722\n",
      "Epoch 6/1000\n",
      "315319/315319 [==============================] - 30s 94us/step - loss: 0.2154 - acc: 0.9226 - val_loss: 0.3964 - val_acc: 0.8730\n",
      "Epoch 7/1000\n",
      "315319/315319 [==============================] - 30s 96us/step - loss: 0.2065 - acc: 0.9257 - val_loss: 0.3956 - val_acc: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a31a66940>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=64, epochs=1000, validation_split=0.1, \\\n",
    "          callbacks=[keras.callbacks.EarlyStopping('val_acc')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3 [1 балл] Оценка качества\n",
    "\n",
    "Протестируйте нейронную сеть на тестовых данных. Используйте accuracy для оценки качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107228/107228 [==============================] - 8s 70us/step\n",
      "0.8908494049994847\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили качество порядка 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4 [1 балл] Оптимизация гиперпарметров\n",
    "\n",
    "В эксперименте участвуют следующие гиперпараметры:\n",
    "* $k$ – размер окна;\n",
    "* $n_h$ – число нейронов на скрытом слое;\n",
    "* $\\theta$ – вид функции активации.\n",
    "\n",
    "Оцените их влияние на качество модели. Как увеличение окна или числа нейронов влияет на итоговый показатель качества? Зависит ли итоговый показатель качества от функции активации на скрытом слое? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_measure_quality(X_train, Y_train, X_test, Y_test, k, n_h, thetha):\n",
    "    print('Building model...')\n",
    "    model = build_model(n_h, k, thetha)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    model.fit(X_train, Y_train, batch_size=64, epochs=1000, validation_split=0.1, \\\n",
    "          callbacks=[keras.callbacks.EarlyStopping('val_acc')])\n",
    "    _, accuracy = model.evaluate(X_test, Y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fit_and_measure_quality(k, n_h, thetha):\n",
    "    print('Loading train dataset...')\n",
    "    X_train, Y_train = prepare_dataset(TRAIN, word_to_idx, embeddings, pos_idx, k)\n",
    "    print('Loading test dataset...')\n",
    "    X_test, Y_test = prepare_dataset(TEST, word_to_idx, embeddings, pos_idx, k)\n",
    "    return fit_and_measure_quality(X_train, Y_train, X_test, Y_test, k, n_h, thetha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим влияние ширины окна на показатель качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for k=1\n",
      "Loading train dataset...\n",
      "Loading test dataset...\n",
      "Building model...\n",
      "Epoch 1/4\n",
      "350355/350355 [==============================] - 11s 31us/step - loss: 0.5107 - acc: 0.8205\n",
      "Epoch 2/4\n",
      "350355/350355 [==============================] - 10s 29us/step - loss: 0.4186 - acc: 0.8428\n",
      "Epoch 3/4\n",
      "350355/350355 [==============================] - 10s 29us/step - loss: 0.4065 - acc: 0.8458\n",
      "Epoch 4/4\n",
      "350355/350355 [==============================] - 12s 34us/step - loss: 0.4006 - acc: 0.8471\n",
      "107228/107228 [==============================] - 6s 53us/step\n",
      "k=1: Accuracy=0.841525\n",
      "Calculating for k=3\n",
      "Loading train dataset...\n",
      "Loading test dataset...\n",
      "Building model...\n",
      "Epoch 1/4\n",
      "350355/350355 [==============================] - 46s 132us/step - loss: 0.4089 - acc: 0.8641\n",
      "Epoch 2/4\n",
      "350355/350355 [==============================] - 21s 61us/step - loss: 0.3018 - acc: 0.8947\n",
      "Epoch 3/4\n",
      "350355/350355 [==============================] - 18s 52us/step - loss: 0.2751 - acc: 0.9032\n",
      "Epoch 4/4\n",
      "350355/350355 [==============================] - 22s 63us/step - loss: 0.2573 - acc: 0.9091\n",
      "107228/107228 [==============================] - 7s 68us/step\n",
      "k=3: Accuracy=0.894039\n",
      "Calculating for k=5\n",
      "Loading train dataset...\n",
      "Loading test dataset...\n",
      "Building model...\n",
      "Epoch 1/4\n",
      "350355/350355 [==============================] - 66s 188us/step - loss: 0.4059 - acc: 0.8668\n",
      "Epoch 2/4\n",
      "350355/350355 [==============================] - 28s 79us/step - loss: 0.2874 - acc: 0.9013\n",
      "Epoch 3/4\n",
      "350355/350355 [==============================] - 27s 77us/step - loss: 0.2529 - acc: 0.9124\n",
      "Epoch 4/4\n",
      "350355/350355 [==============================] - 28s 81us/step - loss: 0.2280 - acc: 0.9202\n",
      "107228/107228 [==============================] - 13s 118us/step\n",
      "k=5: Accuracy=0.897079\n",
      "Calculating for k=7\n",
      "Loading train dataset...\n",
      "Loading test dataset...\n",
      "Building model...\n",
      "Epoch 1/4\n",
      "350355/350355 [==============================] - 226s 646us/step - loss: 0.4113 - acc: 0.8651\n",
      "Epoch 2/4\n",
      "350355/350355 [==============================] - 95s 271us/step - loss: 0.2835 - acc: 0.9028\n",
      "Epoch 3/4\n",
      "350355/350355 [==============================] - 97s 276us/step - loss: 0.2438 - acc: 0.9158\n",
      "Epoch 4/4\n",
      "350355/350355 [==============================] - 93s 266us/step - loss: 0.2135 - acc: 0.9257\n",
      "107228/107228 [==============================] - 31s 286us/step\n",
      "k=7: Accuracy=0.894776\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 3, 5, 7]:\n",
    "    print(\"Calculating for k=%d\" % k)\n",
    "    quality = load_fit_and_measure_quality(k, 128, 'relu')\n",
    "    print(\"k=%d: Accuracy=%f\" % (k, quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что использование окна шириной 3 заметно лучше чем единичное окно, однако дальнейшее увеличение не приводит к сильному росту качества. Хоть и есть некоторый прирост при k=5, он достаточно небольшой, практически в пределах погрешности. Поэтому в дальнейшем будем использовать модель с k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальное значение нейронов скрытого слоя. Обычно для подобного параметра должен быть некоторый минимум, т.к. при небольшом количестве наблюдается недообучение, а при большом напротив - переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "X_train, Y_train = prepare_dataset(TRAIN, word_to_idx, embeddings, pos_idx, k)\n",
    "X_test, Y_test = prepare_dataset(TEST, word_to_idx, embeddings, pos_idx, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for n_h=8\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 18s 58us/step - loss: 0.5683 - acc: 0.8234 - val_loss: 0.4958 - val_acc: 0.8368\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 19s 61us/step - loss: 0.3723 - acc: 0.8763 - val_loss: 0.4664 - val_acc: 0.8450\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 20s 62us/step - loss: 0.3532 - acc: 0.8815 - val_loss: 0.4586 - val_acc: 0.8479\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 18s 57us/step - loss: 0.3440 - acc: 0.8845 - val_loss: 0.4498 - val_acc: 0.8506\n",
      "Epoch 5/1000\n",
      "315319/315319 [==============================] - 18s 58us/step - loss: 0.3379 - acc: 0.8858 - val_loss: 0.4400 - val_acc: 0.8523\n",
      "Epoch 6/1000\n",
      "315319/315319 [==============================] - 18s 58us/step - loss: 0.3333 - acc: 0.8872 - val_loss: 0.4417 - val_acc: 0.8528\n",
      "Epoch 7/1000\n",
      "315319/315319 [==============================] - 18s 58us/step - loss: 0.3298 - acc: 0.8881 - val_loss: 0.4405 - val_acc: 0.8532\n",
      "Epoch 8/1000\n",
      "315319/315319 [==============================] - 20s 63us/step - loss: 0.3271 - acc: 0.8892 - val_loss: 0.4352 - val_acc: 0.8537\n",
      "Epoch 9/1000\n",
      "315319/315319 [==============================] - 18s 59us/step - loss: 0.3251 - acc: 0.8898 - val_loss: 0.4311 - val_acc: 0.8543\n",
      "Epoch 10/1000\n",
      "315319/315319 [==============================] - 19s 60us/step - loss: 0.3231 - acc: 0.8900 - val_loss: 0.4323 - val_acc: 0.8526\n",
      "107228/107228 [==============================] - 7s 67us/step\n",
      "n_h=8: Accuracy=0.876189\n",
      "Calculating for n_h=16\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 22s 71us/step - loss: 0.4719 - acc: 0.8500 - val_loss: 0.4418 - val_acc: 0.8498\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 22s 69us/step - loss: 0.3255 - acc: 0.8885 - val_loss: 0.4214 - val_acc: 0.8549\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 20s 64us/step - loss: 0.3106 - acc: 0.8922 - val_loss: 0.4122 - val_acc: 0.8577\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 22s 69us/step - loss: 0.3025 - acc: 0.8946 - val_loss: 0.4128 - val_acc: 0.8573\n",
      "107228/107228 [==============================] - 7s 68us/step\n",
      "n_h=16: Accuracy=0.879985\n",
      "Calculating for n_h=32\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 28s 89us/step - loss: 0.4281 - acc: 0.8602 - val_loss: 0.4276 - val_acc: 0.8529\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 28s 88us/step - loss: 0.3141 - acc: 0.8915 - val_loss: 0.4168 - val_acc: 0.8580\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 27s 86us/step - loss: 0.2966 - acc: 0.8967 - val_loss: 0.3980 - val_acc: 0.8626\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 26s 83us/step - loss: 0.2847 - acc: 0.9009 - val_loss: 0.3964 - val_acc: 0.8661\n",
      "Epoch 5/1000\n",
      "315319/315319 [==============================] - 27s 86us/step - loss: 0.2752 - acc: 0.9034 - val_loss: 0.3955 - val_acc: 0.8662\n",
      "Epoch 6/1000\n",
      "315319/315319 [==============================] - 26s 83us/step - loss: 0.2683 - acc: 0.9056 - val_loss: 0.3952 - val_acc: 0.8671\n",
      "Epoch 7/1000\n",
      "315319/315319 [==============================] - 26s 84us/step - loss: 0.2620 - acc: 0.9079 - val_loss: 0.3934 - val_acc: 0.8699\n",
      "Epoch 8/1000\n",
      "315319/315319 [==============================] - 27s 86us/step - loss: 0.2565 - acc: 0.9093 - val_loss: 0.3945 - val_acc: 0.8692\n",
      "107228/107228 [==============================] - 8s 71us/step\n",
      "n_h=32: Accuracy=0.888229\n",
      "Calculating for n_h=64\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 31s 99us/step - loss: 0.4022 - acc: 0.8671 - val_loss: 0.4154 - val_acc: 0.8554\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 31s 97us/step - loss: 0.3019 - acc: 0.8951 - val_loss: 0.3909 - val_acc: 0.8627\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 31s 98us/step - loss: 0.2769 - acc: 0.9031 - val_loss: 0.3853 - val_acc: 0.8661\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 30s 96us/step - loss: 0.2610 - acc: 0.9083 - val_loss: 0.3767 - val_acc: 0.8692\n",
      "Epoch 5/1000\n",
      "315319/315319 [==============================] - 31s 97us/step - loss: 0.2490 - acc: 0.9120 - val_loss: 0.3786 - val_acc: 0.8697\n",
      "Epoch 6/1000\n",
      "315319/315319 [==============================] - 30s 96us/step - loss: 0.2398 - acc: 0.9147 - val_loss: 0.3796 - val_acc: 0.8684\n",
      "107228/107228 [==============================] - 11s 100us/step\n",
      "n_h=64: Accuracy=0.889590\n",
      "Calculating for n_h=128\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 38s 122us/step - loss: 0.3833 - acc: 0.8720 - val_loss: 0.4068 - val_acc: 0.8581\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 36s 113us/step - loss: 0.2860 - acc: 0.9004 - val_loss: 0.3795 - val_acc: 0.8656\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 29s 93us/step - loss: 0.2590 - acc: 0.9090 - val_loss: 0.3734 - val_acc: 0.8722\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 137s 435us/step - loss: 0.2411 - acc: 0.9146 - val_loss: 0.3728 - val_acc: 0.8740\n",
      "Epoch 5/1000\n",
      "315319/315319 [==============================] - 32s 100us/step - loss: 0.2274 - acc: 0.9188 - val_loss: 0.3854 - val_acc: 0.8704\n",
      "107228/107228 [==============================] - 9s 80us/step\n",
      "n_h=128: Accuracy=0.888443\n",
      "Calculating for n_h=256\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 60s 191us/step - loss: 0.3683 - acc: 0.8761 - val_loss: 0.3929 - val_acc: 0.8636\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 56s 177us/step - loss: 0.2742 - acc: 0.9039 - val_loss: 0.3757 - val_acc: 0.8700\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 58s 183us/step - loss: 0.2456 - acc: 0.9131 - val_loss: 0.3751 - val_acc: 0.8713\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 56s 179us/step - loss: 0.2258 - acc: 0.9192 - val_loss: 0.3783 - val_acc: 0.8708\n",
      "107228/107228 [==============================] - 13s 119us/step\n",
      "n_h=256: Accuracy=0.893078\n"
     ]
    }
   ],
   "source": [
    "for n_h in [8, 16, 32, 64, 128, 256]:\n",
    "    print(\"Calculating for n_h=%d\" % n_h)\n",
    "    quality = fit_and_measure_quality(X_train, Y_train, X_test, Y_test, k, n_h, 'relu')\n",
    "    print(\"n_h=%d: Accuracy=%f\" % (n_h, quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for n_h=512\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 90s 286us/step - loss: 0.3572 - acc: 0.8787 - val_loss: 0.3856 - val_acc: 0.8659\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 87s 275us/step - loss: 0.2674 - acc: 0.9067 - val_loss: 0.3716 - val_acc: 0.8709\n",
      "Epoch 3/1000\n",
      "315319/315319 [==============================] - 86s 273us/step - loss: 0.2373 - acc: 0.9159 - val_loss: 0.3772 - val_acc: 0.8713\n",
      "Epoch 4/1000\n",
      "315319/315319 [==============================] - 89s 281us/step - loss: 0.2158 - acc: 0.9224 - val_loss: 0.3893 - val_acc: 0.8699\n",
      "107228/107228 [==============================] - 13s 126us/step\n",
      "n_h=512: Accuracy=0.891194\n",
      "Calculating for n_h=1024\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      " 96832/315319 [========>.....................] - ETA: 2:00 - loss: 0.4300 - acc: 0.8568"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-0d58c3c96883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_h\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating for n_h=%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mquality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_and_measure_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_h=%d: Accuracy=%f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-316-9de981f49c32>\u001b[0m in \u001b[0;36mfit_and_measure_quality\u001b[0;34m(X_train, Y_train, X_test, Y_test, k, n_h, thetha)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_h in [512, 1024, 2048]:\n",
    "    print(\"Calculating for n_h=%d\" % n_h)\n",
    "    quality = fit_and_measure_quality(X_train, Y_train, X_test, Y_test, k, n_h, 'relu')\n",
    "    print(\"n_h=%d: Accuracy=%f\" % (n_h, quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем функцию активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for relu\n",
      "Building model...\n",
      "Train on 315319 samples, validate on 35036 samples\n",
      "Epoch 1/1000\n",
      "315319/315319 [==============================] - 48s 152us/step - loss: 0.3680 - acc: 0.8761 - val_loss: 0.4004 - val_acc: 0.8620\n",
      "Epoch 2/1000\n",
      "315319/315319 [==============================] - 55s 175us/step - loss: 0.2751 - acc: 0.9036 - val_loss: 0.3809 - val_acc: 0.8689\n",
      "Epoch 3/1000\n",
      " 19712/315319 [>.............................] - ETA: 52s - loss: 0.2387 - acc: 0.9160"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-322-491e985ddcdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnonlinearity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'selu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating for %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mquality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_and_measure_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"function=%s: Accuracy=%f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-316-9de981f49c32>\u001b[0m in \u001b[0;36mfit_and_measure_quality\u001b[0;34m(X_train, Y_train, X_test, Y_test, k, n_h, thetha)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for nonlinearity in ['relu', 'elu', 'selu', 'sigmoid', 'tanh']:\n",
    "    print(\"Calculating for %s\" % nonlinearity)\n",
    "    quality = fit_and_measure_quality(X_train, Y_train, X_test, Y_test, k, 256, nonlinearity)\n",
    "    print(\"function=%s: Accuracy=%f\" % (nonlinearity, quality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 5 [2 балла] Анализ ошибок\n",
    "1. Привидите примеры из тестового множества, на которых нейронная сеть ошибается. Объясните, почему возникают ошибки.\n",
    "2. Протестируйте нейронную сеть на произвольном предложении (не из тестовых данных). Возникают ли ошибки? Почему?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
